Model,Year,Parameters_Billion,EnergyUsed_MWh,CO2_Tons,Organization,Training_Location,Energy_Efficiency,CO2_per_Parameter
AlexNet,2017,0.06,50,5,University of Toronto,Canada,0.0012,83.33
BERT,2018,0.34,400,35,Google,USA,0.00085,102.94
GPT-2,2019,1.5,1200,120,OpenAI,USA,0.00125,80.00
Megatron-LM,2019,8.3,5800,500,NVIDIA,USA,0.00143,60.24
T5,2020,11,9400,800,Google,USA,0.00117,72.73
GPT-3,2020,175,1300000,552,OpenAI,USA,0.00013,3.15
Switch Transformer,2021,1600,2100000,950,Google,USA,0.00076,0.59
Jurassic-1,2021,178,1200000,600,AI21 Labs,Israel,0.00015,3.37
Codex,2021,12,400000,250,OpenAI,USA,0.00003,20.83
BLOOM,2022,176,1082000,433,BigScience,France,0.00016,2.46
Gopher,2022,280,1900000,750,DeepMind,UK,0.00015,2.68
Chinchilla,2022,70,1000000,480,DeepMind,UK,0.00007,6.86
PaLM,2022,540,2500000,1200,Google,USA,0.00022,2.22
OPT,2022,175,960000,430,Meta,USA,0.00018,2.46
LLaMA,2023,65,900000,360,Meta,USA,0.00007,5.54
GPT-4,2023,1000,3800000,5184,OpenAI,USA,0.00026,5.18
Falcon-180B,2023,180,1100000,510,TII UAE,UAE,0.00016,2.83
Gemini 1.0,2023,600,3500000,2000,Google DeepMind,USA,0.00017,3.33
LLaMA 3.1,2024,405,1700000,8930,Meta,USA,0.00024,22.05
Gemini 1.5,2024,1200,4200000,2150,Google DeepMind,USA,0.00029,1.79
Claude 3 Opus,2024,400,2200000,1050,Anthropic,USA,0.00018,2.63
GPT-5 (est.),2025,2000,6500000,7200,OpenAI,USA,0.00031,3.60
Claude 4 (est.),2025,1000,3800000,3500,Anthropic,USA,0.00026,3.50
Gemini 2 (est.),2025,2200,7000000,6300,Google DeepMind,USA,0.00031,2.86